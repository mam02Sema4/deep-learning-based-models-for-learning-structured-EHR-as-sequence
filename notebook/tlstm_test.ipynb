{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T13:00:10.997343Z",
     "start_time": "2020-08-15T13:00:10.993066Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.5.0', '2.2.0')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "import tensorflow as tf\n",
    "torch.__version__, tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## convert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T02:54:04.640672Z",
     "start_time": "2020-07-30T02:54:04.635997Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "def load(fn):\n",
    "    with open(fn, \"rb\") as f:\n",
    "        data = pickle.load(f, encoding='latin1')\n",
    "    return data\n",
    "\n",
    "def load1(fn):\n",
    "    with open(fn, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def save(data, fn):\n",
    "    with open(fn, \"wb\") as f:\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T02:53:34.927775Z",
     "start_time": "2020-07-30T02:53:34.925266Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "old = \"../../../../../py2/T-LSTM-master/Split0/\"\n",
    "newp = \"../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T02:54:50.820721Z",
     "start_time": "2020-07-30T02:54:49.457240Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_train (2078, 2)\n",
      "label_train (2078, 2)\n",
      "label_test (891, 2)\n",
      "label_test (891, 2)\n",
      "hidden_ind_train (2078, 4, 1)\n",
      "hidden_ind_train (2078, 4, 1)\n",
      "hidden_ind_test (891, 4, 1)\n",
      "hidden_ind_test (891, 4, 1)\n",
      "elapsed_test (891, 1, 4)\n",
      "elapsed_test (891, 1, 4)\n",
      "elapsed_train (2078, 1, 4)\n",
      "elapsed_train (2078, 1, 4)\n",
      "data_test (891, 4, 529)\n",
      "data_test (891, 4, 529)\n",
      "accum_elapsed_train (2078, 4, 4)\n",
      "accum_elapsed_train (2078, 4, 4)\n",
      "accum_elapsed_test (891, 4, 4)\n",
      "accum_elapsed_test (891, 4, 4)\n",
      "data_train (2078, 4, 529)\n",
      "data_train (2078, 4, 529)\n"
     ]
    }
   ],
   "source": [
    "for each in Path(old).glob(\"*\"):\n",
    "    nf = Path(newp) / each.name\n",
    "    data = load(each)\n",
    "    print(each.stem, data[1].shape)\n",
    "    save(data, nf)\n",
    "    nd = load1(nf)\n",
    "    print(nf.stem, nd[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Translation tf to pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T20:04:39.428961Z",
     "start_time": "2020-07-24T20:04:39.425082Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=1.0>, TensorShape([]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(1, dtype=tf.float32), tf.constant(1, dtype=tf.float32).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T20:04:35.966571Z",
     "start_time": "2020-07-24T20:04:35.961892Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.), torch.Size([]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(2, dtype=torch.float32), torch.tensor(2, dtype=torch.float32).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T20:12:26.299566Z",
     "start_time": "2020-07-24T20:12:26.294616Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 10), dtype=float32, numpy=array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>,\n",
       " TensorShape([1, 10]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones([1, 10], dtype=tf.float32), tf.ones([1, 10], dtype=tf.float32).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T20:12:29.750002Z",
     "start_time": "2020-07-24T20:12:29.745095Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]), torch.Size([1, 10]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((1,10), dtype=torch.float32), torch.ones((1,10), dtype=torch.float32).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T20:29:25.866561Z",
     "start_time": "2020-07-24T20:29:25.859754Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[9.951922]], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.math.log(tf.constant([[0.2, 0.5, 1, 5]]) + tf.constant(1.0))\n",
    "b = tf.math.divide(tf.constant(1.0), a)\n",
    "c = tf.ones([1, 4], tf.float32)\n",
    "b.shape, tf.ones([1, 4]).shape\n",
    "tf.matmul(b, tf.ones([4, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T20:30:39.718067Z",
     "start_time": "2020-07-24T20:30:39.711342Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[9.9519]]), tensor([[9.9519]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.log(torch.tensor([[0.2, 0.5, 1, 5]]) + torch.tensor(1, dtype=torch.float32))\n",
    "b = torch.div(torch.tensor(1, dtype=torch.float32), a)\n",
    "c = torch.ones((4,1), dtype=torch.float32)\n",
    "b @ c, torch.matmul(b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T23:45:07.657227Z",
     "start_time": "2020-07-24T23:45:07.652840Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.1823, 0.4055],\n",
       "        [0.6931, 1.7918]], requires_grad=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parameter(torch.Tensor(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T02:14:23.177675Z",
     "start_time": "2020-07-25T02:14:23.168099Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9572],\n",
      "         [0.4080],\n",
      "         [0.6568]],\n",
      "\n",
      "        [[0.3190],\n",
      "         [0.7185],\n",
      "         [0.3163]]]) tensor([[[0.8835, 0.2457, 0.1546, 0.7032],\n",
      "         [0.1824, 0.5793, 0.6159, 0.9758],\n",
      "         [0.2774, 0.1703, 0.1724, 0.2960]],\n",
      "\n",
      "        [[0.3209, 0.1021, 0.8421, 0.5318],\n",
      "         [0.5956, 0.3149, 0.6690, 0.6734],\n",
      "         [0.1413, 0.3545, 0.4481, 0.5095]]])\n",
      "tensor([[[0.9572, 0.8835, 0.2457, 0.1546, 0.7032],\n",
      "         [0.4080, 0.1824, 0.5793, 0.6159, 0.9758],\n",
      "         [0.6568, 0.2774, 0.1703, 0.1724, 0.2960]],\n",
      "\n",
      "        [[0.3190, 0.3209, 0.1021, 0.8421, 0.5318],\n",
      "         [0.7185, 0.5956, 0.3149, 0.6690, 0.6734],\n",
      "         [0.3163, 0.1413, 0.3545, 0.4481, 0.5095]]])\n",
      "index:  0\n",
      "tensor([[0.9572, 0.8835, 0.2457, 0.1546, 0.7032],\n",
      "        [0.3190, 0.3209, 0.1021, 0.8421, 0.5318]])\n",
      "index:  1\n",
      "tensor([[0.4080, 0.1824, 0.5793, 0.6159, 0.9758],\n",
      "        [0.7185, 0.5956, 0.3149, 0.6690, 0.6734]])\n",
      "index:  2\n",
      "tensor([[0.6568, 0.2774, 0.1703, 0.1724, 0.2960],\n",
      "        [0.3163, 0.1413, 0.3545, 0.4481, 0.5095]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand((2,3,1))\n",
    "b = torch.rand((2,3,4))\n",
    "print(a, b)\n",
    "\n",
    "c = torch.cat((a, b), dim=2)\n",
    "print(c)\n",
    "\n",
    "for t in range(3):\n",
    "    print(\"index: \", t)\n",
    "    print(c[:, t, :])\n",
    "#     print(c[:, t, 0])\n",
    "#     print(c[:, t, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T14:43:57.810489Z",
     "start_time": "2020-07-25T14:43:57.805879Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[0.3412673 , 0.6143132 , 0.30103528, 0.42347988],\n",
       "        [0.06384967, 0.01151462, 0.07089078, 0.04680625],\n",
       "        [0.03913313, 0.01505405, 0.03377762, 0.04127943]],\n",
       "\n",
       "       [[0.34445944, 0.3457046 , 0.11317814, 0.22907218],\n",
       "        [0.35396236, 0.98564976, 0.82023317, 0.9243021 ],\n",
       "        [0.13246745, 0.17909516, 0.09095483, 0.05182858]]], dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.multiply(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T14:48:33.641924Z",
     "start_time": "2020-07-25T14:48:33.637759Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3413, 0.6143, 0.3010, 0.4235],\n",
       "         [0.0638, 0.0115, 0.0709, 0.0468],\n",
       "         [0.0391, 0.0151, 0.0338, 0.0413]],\n",
       "\n",
       "        [[0.3445, 0.3457, 0.1132, 0.2291],\n",
       "         [0.3540, 0.9856, 0.8202, 0.9243],\n",
       "         [0.1325, 0.1791, 0.0910, 0.0518]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T01:41:51.693642Z",
     "start_time": "2020-07-26T01:41:51.687487Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4]) tensor([[[0.5134, 0.9242, 0.4529, 0.6371],\n",
      "         [0.4035, 0.0728, 0.4480, 0.2958],\n",
      "         [0.9435, 0.3630, 0.8144, 0.9952]],\n",
      "\n",
      "        [[0.9117, 0.9150, 0.2996, 0.6063],\n",
      "         [0.3567, 0.9934, 0.8267, 0.9316],\n",
      "         [0.4794, 0.6481, 0.3292, 0.1876]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 3, 4]),\n",
       " tensor([[[[0.5134, 0.9242, 0.4529, 0.6371],\n",
       "           [0.4035, 0.0728, 0.4480, 0.2958],\n",
       "           [0.9435, 0.3630, 0.8144, 0.9952]],\n",
       " \n",
       "          [[0.9117, 0.9150, 0.2996, 0.6063],\n",
       "           [0.3567, 0.9934, 0.8267, 0.9316],\n",
       "           [0.4794, 0.6481, 0.3292, 0.1876]]]]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(b.shape, b)\n",
    "bu = torch.unsqueeze(b, 0)\n",
    "bu.shape, bu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T01:43:34.778530Z",
     "start_time": "2020-07-26T01:43:34.773394Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2, 3, 4]),\n",
       " tensor([[[[0.5134, 0.9242, 0.4529, 0.6371],\n",
       "           [0.4035, 0.0728, 0.4480, 0.2958],\n",
       "           [0.9435, 0.3630, 0.8144, 0.9952]],\n",
       " \n",
       "          [[0.9117, 0.9150, 0.2996, 0.6063],\n",
       "           [0.3567, 0.9934, 0.8267, 0.9316],\n",
       "           [0.4794, 0.6481, 0.3292, 0.1876]]],\n",
       " \n",
       " \n",
       "         [[[0.5134, 0.9242, 0.4529, 0.6371],\n",
       "           [0.4035, 0.0728, 0.4480, 0.2958],\n",
       "           [0.9435, 0.3630, 0.8144, 0.9952]],\n",
       " \n",
       "          [[0.9117, 0.9150, 0.2996, 0.6063],\n",
       "           [0.3567, 0.9934, 0.8267, 0.9316],\n",
       "           [0.4794, 0.6481, 0.3292, 0.1876]]]]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buc = torch.cat([bu, bu], 0)\n",
    "buc.shape, buc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T01:45:55.122582Z",
     "start_time": "2020-07-26T01:45:55.117790Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.5134, 0.9242, 0.4529, 0.6371],\n",
       "          [0.4035, 0.0728, 0.4480, 0.2958],\n",
       "          [0.9435, 0.3630, 0.8144, 0.9952]],\n",
       "\n",
       "         [[0.5134, 0.9242, 0.4529, 0.6371],\n",
       "          [0.4035, 0.0728, 0.4480, 0.2958],\n",
       "          [0.9435, 0.3630, 0.8144, 0.9952]]],\n",
       "\n",
       "\n",
       "        [[[0.9117, 0.9150, 0.2996, 0.6063],\n",
       "          [0.3567, 0.9934, 0.8267, 0.9316],\n",
       "          [0.4794, 0.6481, 0.3292, 0.1876]],\n",
       "\n",
       "         [[0.9117, 0.9150, 0.2996, 0.6063],\n",
       "          [0.3567, 0.9934, 0.8267, 0.9316],\n",
       "          [0.4794, 0.6481, 0.3292, 0.1876]]]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buc.transpose(0, 1).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T21:18:51.982865Z",
     "start_time": "2020-07-30T21:18:51.979604Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bb = torch.rand(3,2,4)\n",
    "tt =  torch.tensor([[[1],[1]], [[1],[1]],[[1],[1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T21:17:22.291276Z",
     "start_time": "2020-07-30T21:17:22.275927Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from enum import IntEnum\n",
    "class Dim(IntEnum):\n",
    "    batch = 0\n",
    "    seq = 1\n",
    "    feature = 2\n",
    "    \n",
    "class NaiveLSTM(nn.Module):\n",
    "    def __init__(self, input_sz: int, hidden_sz: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_sz\n",
    "        self.hidden_size = hidden_sz\n",
    "        # input gate\n",
    "        self.W_ii = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.W_hi = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_i = Parameter(torch.Tensor(hidden_sz))\n",
    "        # forget gate\n",
    "        self.W_if = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.W_hf = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_f = Parameter(torch.Tensor(hidden_sz))\n",
    "        # ???\n",
    "        self.W_ig = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.W_hg = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_g = Parameter(torch.Tensor(hidden_sz))\n",
    "        # output gate\n",
    "        self.W_io = Parameter(torch.Tensor(input_sz, hidden_sz))\n",
    "        self.W_ho = Parameter(torch.Tensor(hidden_sz, hidden_sz))\n",
    "        self.b_o = Parameter(torch.Tensor(hidden_sz))\n",
    "         \n",
    "        self.init_weights()\n",
    "     \n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2:\n",
    "                nn.init.xavier_uniform_(p.data)\n",
    "            else:\n",
    "                nn.init.zeros_(p.data)\n",
    "         \n",
    "    def forward(self, x: torch.Tensor, init_states=None):\n",
    "        \"\"\"Assumes x is of shape (batch, sequence, feature)\"\"\"\n",
    "        bs, seq_sz, _ = x.size()\n",
    "        hidden_seq = []\n",
    "        if init_states is None:\n",
    "            h_t, c_t = torch.zeros(self.hidden_size).to(x.device), torch.zeros(self.hidden_size).to(x.device)\n",
    "        else:\n",
    "            h_t, c_t = init_states\n",
    "        for t in range(seq_sz): # iterate over the time steps\n",
    "            x_t = x[:, t, :]\n",
    "            i_t = torch.sigmoid(x_t @ self.W_ii + h_t @ self.W_hi + self.b_i)\n",
    "            f_t = torch.sigmoid(x_t @ self.W_if + h_t @ self.W_hf + self.b_f)\n",
    "            g_t = torch.tanh(x_t @ self.W_ig + h_t @ self.W_hg + self.b_g)\n",
    "            o_t = torch.sigmoid(x_t @ self.W_io + h_t @ self.W_ho + self.b_o)\n",
    "            c_t = f_t * c_t + i_t * g_t\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "            hidden_seq.append(h_t)\n",
    "            \n",
    "        hidden_seq = torch.cat(hidden_seq, dim=Dim.batch)\n",
    "        print(hidden_seq.shape)\n",
    "        # reshape from shape (sequence, batch, feature) to (batch, sequence, feature)\n",
    "        hidden_seq = hidden_seq.transpose(Dim.batch, Dim.seq).contiguous()\n",
    "        return hidden_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T21:17:22.842584Z",
     "start_time": "2020-07-30T21:17:22.839435Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lstm = NaiveLSTM(4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T21:17:31.105927Z",
     "start_time": "2020-07-30T21:17:31.097796Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 10])\n",
      "torch.Size([6, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1361,  0.0406,  0.0749,  0.0387,  0.1307,  0.1851],\n",
       "         [ 0.1331,  0.0736,  0.1242,  0.1694,  0.1198,  0.1751],\n",
       "         [ 0.1248,  0.0456,  0.0743,  0.1025,  0.0458,  0.0917],\n",
       "         [ 0.1198,  0.0404,  0.1143,  0.1304,  0.1379,  0.1660],\n",
       "         [ 0.1378,  0.1078,  0.0768,  0.2108,  0.0996,  0.1583],\n",
       "         [-0.0775, -0.0885, -0.0784, -0.1604, -0.1456, -0.1419],\n",
       "         [-0.1670, -0.0864, -0.1816, -0.2897, -0.2577, -0.2607],\n",
       "         [-0.1185,  0.0315, -0.1447, -0.0685, -0.1150, -0.1039],\n",
       "         [ 0.1373, -0.0146,  0.1442,  0.1815,  0.1191,  0.1462],\n",
       "         [ 0.1391,  0.0119,  0.1512,  0.1177,  0.1031,  0.0860]],\n",
       "        grad_fn=<CopyBackwards>),\n",
       " torch.Size([10, 6]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = torch.tensor([[0,1], [1,0], [0,1]])\n",
    "lstm(bb), lstm(bb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([1, 3, 4])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([1, 3, 4])\n",
      "torch.Size([4, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 1], grad_fn=<NotImplemented>)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(lstm(b)[:, -1, :], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T15:08:05.539866Z",
     "start_time": "2020-08-14T15:08:05.536030Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,0], [0,1]],dtype=torch.float32).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7683)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.BCEWithLogitsLoss()(torch.tensor([[0.1, 0.8],[0.3, 0.7]]), torch.tensor([[1,0], [0,1]],dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T15:10:47.650205Z",
     "start_time": "2020-08-14T15:10:47.638477Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3318, 0.6682],\n",
      "        [0.4013, 0.5987]])\n",
      "tensor([[-1.1032, -0.0000],\n",
      "        [-0.0000, -0.5130]])\n",
      "tensor([1.1032, 0.5130])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1.1032],\n",
       "         [0.5130]]),\n",
       " tensor(0.8081))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class masked_softmax_cross_entropy_loss(nn.Module):\n",
    "    def __init__(self, weight=None):\n",
    "        super(masked_softmax_cross_entropy_loss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if not target.is_same_size(input):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(target.size(), input.size()))\n",
    "\n",
    "        inputs = F.softmax(input, dim=1)\n",
    "        print(inputs)\n",
    "        print(target * torch.log(inputs))\n",
    "        loss = -torch.sum(target * torch.log(inputs), 1)\n",
    "        print(loss)\n",
    "        loss = torch.unsqueeze(loss, 1)\n",
    "        return loss\n",
    "    \n",
    "x = masked_softmax_cross_entropy_loss()(torch.tensor([[0.1, 0.8],[0.3, 0.7]]), torch.tensor([[1,0], [0,1]], dtype=torch.float32))\n",
    "x, torch.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T21:21:36.031198Z",
     "start_time": "2020-07-30T21:21:35.994795Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.1031861, 0.5130153], dtype=float32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax_cross_entropy_with_logits(labels=[[1,0],[0,1]], logits=[[0.1, 0.8],[0.3, 0.7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T21:19:12.120961Z",
     "start_time": "2020-07-30T21:19:12.093152Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch import nn as N\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TLSTMConfig:\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, fc_dim, dropoutput_rate):\n",
    "        self.dropout_prob = dropoutput_rate\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.fc_dim = fc_dim\n",
    "\n",
    "\n",
    "class SoftmaxCrossEntropyLoss(N.Module):\n",
    "    \"\"\"\n",
    "    equivalent implementation of tf.nn.softmax_cross_entropy_with_logits\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weight=None):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if not targets.is_same_size(inputs):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(targets.size(),\n",
    "                                                                                           inputs.size()))\n",
    "\n",
    "        inputs = F.softmax(inputs, dim=1)\n",
    "        loss = -torch.sum(targets * torch.log(inputs), 1)\n",
    "        loss = torch.unsqueeze(loss, 1)\n",
    "        return torch.mean(loss)\n",
    "\n",
    "\n",
    "class TLSTMCell(N.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.Wi = Parameter(torch.Tensor(input_dim, hidden_dim))\n",
    "        self.Ui = Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
    "        self.bi = Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "        self.Wf = Parameter(torch.Tensor(input_dim, hidden_dim))\n",
    "        self.Uf = Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
    "        self.bf = Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "        self.Wog = Parameter(torch.Tensor(input_dim, hidden_dim))\n",
    "        self.Uog = Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
    "        self.bog = Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "        self.Wc = Parameter(torch.Tensor(input_dim, hidden_dim))\n",
    "        self.Uc = Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
    "        self.bc = Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "        self.W_decomp = Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
    "        self.b_decomp = Parameter(torch.Tensor(hidden_dim))\n",
    "\n",
    "    def init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.data.ndimension() >= 2:\n",
    "                N.init.xavier_uniform_(p.data)\n",
    "            else:\n",
    "                N.init.zeros_(p.data)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, time: torch.Tensor, prev_hidden_state=None):\n",
    "        # x has three dim: batch size(pats), seq_size(encounters), v_dim(features)\n",
    "        bz, seq_sz, v_dim = x.size()\n",
    "        tbz, tseq_sz, tv_dim = time.size()\n",
    "        assert bz == tbz and seq_sz == tseq_sz, \\\n",
    "            \"feature and time seq have different batch size {}-{} or seq len {}-{}\".format(bz, tbz, seq_sz, tseq_sz)\n",
    "\n",
    "        # init hidden if no previous hidden\n",
    "        if prev_hidden_state is None:\n",
    "            h_t, c_t = torch.zeros(self.hidden_dim).to(x.device), torch.zeros(self.hidden_dim).to(x.device)\n",
    "        else:\n",
    "            h_t, c_t = prev_hidden_state\n",
    "\n",
    "        # recurrent loop\n",
    "        hidden_seq = []\n",
    "        for i, t in enumerate(range(seq_sz)):\n",
    "            x_t = x[:, t, :]  # (batch, input)\n",
    "            # process time difference\n",
    "            t_t = time[:, t, :]\n",
    "            T = self.map_elapse_time(t_t)\n",
    "            C_ST = torch.tanh(torch.matmul(c_t, self.W_decomp) + self.b_decomp)\n",
    "            C_ST_dis = torch.mul(T, C_ST)\n",
    "            c_t = c_t - C_ST + C_ST_dis\n",
    "            # input gate\n",
    "            i_t = torch.sigmoid(torch.matmul(x_t, self.Wi) + torch.matmul(h_t, self.Ui) + self.bi)\n",
    "            # forget gate\n",
    "            f_t = torch.sigmoid(torch.matmul(x_t, self.Wf) + torch.matmul(h_t, self.Uf) + self.bf)\n",
    "            # output gate\n",
    "            o_t = torch.sigmoid(torch.matmul(x_t, self.Wog) + torch.matmul(h_t, self.Uog) + self.bog)\n",
    "            # cadidate MemCell\n",
    "            C = torch.tanh(torch.matmul(x_t, self.Wc) + torch.matmul(h_t, self.Uc) + self.bc)\n",
    "            # current MemCell\n",
    "            c_t = f_t * c_t + i_t * C\n",
    "            # current hidden state\n",
    "            h_t = o_t * torch.tanh(c_t)\n",
    "            # hidden_seq.append(torch.stack((c_h_t, C_t)))\n",
    "            hidden_seq.append(h_t.unsqueeze(0))  # create extra dim for later concat (seq, batch, input)\n",
    "\n",
    "        hidden_seq = torch.cat(hidden_seq, dim=0)  # concat to get the seq dim back (seq, batch, input)\n",
    "        # hidden_seq = hidden_seq.transpose(0, 1).contiguous()  # (seq, batch, input) => (batch, seq, input)\n",
    "        return hidden_seq, (h_t, c_t)\n",
    "    \n",
    "    def map_elapse_time(self, t):\n",
    "        c1 = torch.tensor(1, dtype=torch.float32)\n",
    "        c2 = torch.tensor(np.e, dtype=torch.float32)\n",
    "\n",
    "        T = torch.div(c1, torch.log(t + c2))\n",
    "        grid = torch.ones((1, self.hidden_dim), dtype=torch.float32)\n",
    "        return torch.matmul(T, grid)\n",
    "\n",
    "class TLSTM(N.Module):\n",
    "\n",
    "    def __init__(self, config=None):\n",
    "        super().__init__()\n",
    "        # self.fc_dim = fc_dim\n",
    "        # self.output_dim = output_dim\n",
    "        self.tlstm = TLSTMCell(config.input_dim, config.hidden_dim)\n",
    "        self.dropout_prob = config.dropout_prob\n",
    "        self.fc_layer = N.Linear(config.hidden_dim, config.fc_dim)\n",
    "        self.output_layer = N.Linear(config.fc_dim, config.output_dim)\n",
    "\n",
    "        # we can use pytorch default implementation of binary loss function - BCEWithLogitsLoss\n",
    "        # but we found the output did not exactly match the tf.nn.softmax_cross_entropy_with_logits with mean reduce\n",
    "        # To make sure, results repeatable, we will use SoftmaxCrossEntropyLoss for now\n",
    "        # self.loss_fct = N.BCEWithLogitsLoss()\n",
    "        self.loss_fct = SoftmaxCrossEntropyLoss()\n",
    "\n",
    "    def forward(self, feature, time, labels):\n",
    "        # get raw logits\n",
    "        seq, (h_t, c_t) = self.tlstm(feature, time)\n",
    "        # seq = seq[-1, :, :]  # (seq, batch, input); get the last seq for classification\n",
    "        last_state = h_t\n",
    "        last_state = F.relu(self.fc_layer(last_state))\n",
    "        last_state = F.dropout(last_state, p=self.dropout_prob)\n",
    "        logits = self.output_layer(last_state)\n",
    "\n",
    "        # measure loss\n",
    "        loss = self.loss_fct(logits, labels)\n",
    "        return loss, logits, torch.argmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T21:19:55.004232Z",
     "start_time": "2020-07-30T21:19:54.994458Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9261, 0.3319, 0.3081, 0.7040],\n",
      "         [0.8074, 0.4562, 0.1841, 0.8379]],\n",
      "\n",
      "        [[0.0504, 0.1540, 0.1602, 0.4930],\n",
      "         [0.1777, 0.0024, 0.8727, 0.8469]],\n",
      "\n",
      "        [[0.7725, 0.0687, 0.1997, 0.7045],\n",
      "         [0.9790, 0.6107, 0.9465, 0.0355]]]) tensor([[[1],\n",
      "         [1]],\n",
      "\n",
      "        [[1],\n",
      "         [1]],\n",
      "\n",
      "        [[1],\n",
      "         [1]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.7080, grad_fn=<MeanBackward0>),\n",
       " tensor([[-0.1574, -0.2433],\n",
       "         [-0.1709, -0.2187],\n",
       "         [-0.1709, -0.2187]], grad_fn=<AddmmBackward>),\n",
       " tensor([0, 0, 0], grad_fn=<NotImplemented>))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = TLSTMConfig(4, 2, 10, 5, 0.1)\n",
    "t = TLSTM(config)\n",
    "label = torch.tensor([[0,1], [1,0], [0,1]], dtype=torch.float32)\n",
    "print(bb, tt)\n",
    "t(bb, tt, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T20:58:43.822672Z",
     "start_time": "2020-07-30T20:58:43.819159Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tlstm.Wi\n",
      "tlstm.Ui\n",
      "tlstm.bi\n",
      "tlstm.Wf\n",
      "tlstm.Uf\n",
      "tlstm.bf\n",
      "tlstm.Wog\n",
      "tlstm.Uog\n",
      "tlstm.bog\n",
      "tlstm.Wc\n",
      "tlstm.Uc\n",
      "tlstm.bc\n",
      "tlstm.W_decomp\n",
      "tlstm.b_decomp\n",
      "fc_layer.weight\n",
      "fc_layer.bias\n",
      "output_layer.weight\n",
      "output_layer.bias\n"
     ]
    }
   ],
   "source": [
    "# list(t.named_parameters())\n",
    "for n, p in t.named_parameters():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T21:32:35.747320Z",
     "start_time": "2020-07-30T21:32:35.742482Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2, 4]), TensorShape([4, 3, 2]), TensorShape([2, 3, 4]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbb = tf.transpose(bb, perm=[2,0,1])\n",
    "ttbb = tf.transpose(tbb)\n",
    "bb.shape, tbb.shape, ttbb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T22:47:21.997194Z",
     "start_time": "2020-07-30T22:47:21.993879Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.92605263 0.3318926  0.30814034 0.70401543]\n",
      "  [0.05036551 0.1540097  0.16021532 0.49301505]\n",
      "  [0.7725034  0.06866723 0.19968963 0.704536  ]]\n",
      "\n",
      " [[0.8074291  0.45615095 0.18412828 0.83786315]\n",
      "  [0.17769796 0.00238603 0.8726631  0.8469192 ]\n",
      "  [0.9789614  0.6106911  0.9465321  0.03552949]]], shape=(2, 3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(ttbb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T22:47:13.020530Z",
     "start_time": "2020-07-30T22:47:13.015712Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 4]),\n",
       " tensor([[[0.9261, 0.3319, 0.3081, 0.7040],\n",
       "          [0.0504, 0.1540, 0.1602, 0.4930],\n",
       "          [0.7725, 0.0687, 0.1997, 0.7045]],\n",
       " \n",
       "         [[0.8074, 0.4562, 0.1841, 0.8379],\n",
       "          [0.1777, 0.0024, 0.8727, 0.8469],\n",
       "          [0.9790, 0.6107, 0.9465, 0.0355]]]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptb = torch.transpose(bb, 1, 0)\n",
    "ptb.shape, ptb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## debuging tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T21:15:04.879400Z",
     "start_time": "2020-07-30T21:15:04.820048Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\n",
    "tr = load1(\"../../data/data_train.pkl\")\n",
    "ti = load1(\"../../data/elapsed_train.pkl\")\n",
    "l = load1(\"../../data/label_train.pkl\")\n",
    "len(tr), len(ti), len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T22:52:16.661908Z",
     "start_time": "2020-07-30T22:52:16.655423Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 4, 1), dtype=float32, numpy=\n",
       " array([[[0.92605263],\n",
       "         [0.3318926 ],\n",
       "         [0.30814034],\n",
       "         [0.70401543]],\n",
       " \n",
       "        [[0.8074291 ],\n",
       "         [0.45615095],\n",
       "         [0.18412828],\n",
       "         [0.83786315]]], dtype=float32)>,\n",
       " TensorShape([2, 4, 1]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb0 = bb[0]\n",
    "print(bb0.shape)\n",
    "trb = tf.reshape(bb0, [tf.shape(bb0)[0],tf.shape(bb0)[1],1])\n",
    "trb, trb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T22:55:23.361597Z",
     "start_time": "2020-07-30T22:55:23.356832Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9261],\n",
       "         [0.3319],\n",
       "         [0.3081],\n",
       "         [0.7040]],\n",
       "\n",
       "        [[0.8074],\n",
       "         [0.4562],\n",
       "         [0.1841],\n",
       "         [0.8379]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb0.view(bb0.shape[0], bb0.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T22:59:38.756597Z",
     "start_time": "2020-07-30T22:59:38.750358Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(536, 3, 529) (536, 1, 3) (536, 2)\n",
      "(536, 3)\n",
      "torch.Size([3, 536])\n",
      "torch.Size([3, 536, 1])\n",
      "(536, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "for a, b, c in zip(tr, ti, l):\n",
    "    print(a.shape, b.shape, c.shape)\n",
    "    nb = np.reshape(b, [b.shape[0], b.shape[2]])\n",
    "    print(nb.shape)\n",
    "    nb = torch.tensor(nb)\n",
    "    nb = torch.transpose(nb, 1, 0)\n",
    "    print(nb.shape)\n",
    "    nb = nb.view(nb.shape[0], nb.shape[1], 1)\n",
    "    print(nb.shape)\n",
    "    nb2 = np.reshape(b, [b.shape[0], b.shape[2], b.shape[1]])\n",
    "    print(nb2.shape)\n",
    "#     print(torch.tensor(a))\n",
    "#     print(torch.tensor(b))\n",
    "#     print(torch.tensor(c, dtype=torch.float32))\n",
    "#     ta = torch.tensor(a)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T15:46:44.016100Z",
     "start_time": "2020-08-03T15:46:44.010217Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.2100, 0.1395],\n",
       "          [0.0328, 0.4370],\n",
       "          [0.0646, 0.3752]],\n",
       " \n",
       "         [[0.1856, 0.2564],\n",
       "          [0.2829, 0.5191],\n",
       "          [0.1522, 0.5017]]]),\n",
       " tensor([[[-0.6585, -0.7290],\n",
       "          [-0.9155, -0.5114],\n",
       "          [-0.8605, -0.5499]],\n",
       " \n",
       "         [[-0.7292, -0.6584],\n",
       "          [-0.8182, -0.5820],\n",
       "          [-0.8831, -0.5336]]]),\n",
       " tensor([[[-0.6585, -0.7290],\n",
       "          [-0.9155, -0.5114],\n",
       "          [-0.8605, -0.5499]],\n",
       " \n",
       "         [[-0.7292, -0.6584],\n",
       "          [-0.8182, -0.5820],\n",
       "          [-0.8831, -0.5336]]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.rand((2,3,2))\n",
    "b, F.log_softmax(b, dim=2), torch.log(F.softmax(b, dim=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cat+time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T14:36:09.500714Z",
     "start_time": "2020-08-15T14:36:09.494483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([1., 0., 0., 1., 1.]),\n",
       "  tensor([[[0.0289, 0.1848, 0.9356,  ..., 0.3355, 0.0893, 0.2524],\n",
       "           [0.9931, 0.0061, 0.8767,  ..., 0.7025, 0.6984, 0.4814],\n",
       "           [0.2147, 0.4837, 0.6908,  ..., 0.4290, 0.2049, 0.2470],\n",
       "           ...,\n",
       "           [0.1878, 0.6946, 0.4514,  ..., 0.6873, 0.1776, 0.1476],\n",
       "           [0.6431, 0.9657, 0.5513,  ..., 0.9069, 0.1516, 0.5305],\n",
       "           [0.3446, 0.0547, 0.4428,  ..., 0.4741, 0.8503, 0.1679]]])),\n",
       " torch.Size([1, 182, 10]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data format\n",
    "d = (\n",
    "    torch.tensor([1,0,0,1,1], dtype=torch.float32),\n",
    "    torch.rand((1,182,10))\n",
    ")\n",
    "d, d[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T14:35:41.879196Z",
     "start_time": "2020-08-15T14:35:41.861763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1406, -0.3870]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "# continuous vars\n",
    "ecoder1 = nn.LSTM(10, 2, num_layers=1, batch_first=True)\n",
    "t1 = ecoder1(d[1])[1][0]\n",
    "print(t1)\n",
    "t1 = torch.squeeze(t1, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T14:35:44.741154Z",
     "start_time": "2020-08-15T14:35:44.737256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5153,  0.9061], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# categorical vars\n",
    "ecoder2 = nn.Linear(5, 2)\n",
    "t2 = ecoder2(d[0])\n",
    "print(t2)\n",
    "t2 = torch.unsqueeze(t2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T14:35:46.575358Z",
     "start_time": "2020-08-15T14:35:46.570970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1406, -0.3870, -0.5153,  0.9061]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([t1, t2], dim=1) # combined representations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
